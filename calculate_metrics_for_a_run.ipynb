{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:24.524147Z",
     "start_time": "2025-01-15T22:37:24.513352Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "a03d32b1ca9a396f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:26.358361Z",
     "start_time": "2025-01-15T22:37:24.526879Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from calculate_metric import get_stats_for_state\n",
    "from visualize_actor import get_state_traj\n"
   ],
   "id": "8b024d1e9cfcad0",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:32.738059Z",
     "start_time": "2025-01-15T22:37:26.428457Z"
    }
   },
   "source": [
    "artifact_version = \"286\"\n",
    "num_episodes = 100\n",
    "model_artifact_remote_name = (\n",
    "    f\"josssdan/JaxInforMARL/PPO_RNN_Runner_State:v{artifact_version}\"\n",
    ")\n",
    "\n",
    "traj_batch, config, env = get_state_traj(model_artifact_remote_name, artifact_version, num_episodes)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'derived_values': {'minibatch_size': 12800,\n",
      "                    'num_actors': 200,\n",
      "                    'num_updates': 78,\n",
      "                    'scaled_clip_eps': 0.2},\n",
      " 'env_config': {'env_cls_name': 'TargetMPEEnvironment',\n",
      "                'env_kwargs': {'agent_communication_type': None,\n",
      "                               'agent_control_noise_std': 0.0,\n",
      "                               'agent_max_speed': -1,\n",
      "                               'agent_visibility_radius': [0],\n",
      "                               'dist_to_goal_reward_ratio': 0.9,\n",
      "                               'entities_initial_coord_radius': [1],\n",
      "                               'entity_acceleration': 5,\n",
      "                               'max_steps': 25,\n",
      "                               'num_agents': 2,\n",
      "                               'one_time_death_reward': 15}},\n",
      " 'network_config': {'actor_num_hidden_linear_layer': 2,\n",
      "                    'critic_num_hidden_linear_layer': 2,\n",
      "                    'entity_type_embedding_dim': 4,\n",
      "                    'fc_dim_size': 8,\n",
      "                    'graph_attention_key_dim': 8,\n",
      "                    'graph_hidden_feature_dim': 8,\n",
      "                    'graph_num_linear_layer': 2,\n",
      "                    'gru_hidden_dim': 8,\n",
      "                    'num_graph_attn_layers': 1,\n",
      "                    'num_heads_per_attn_layer': 2},\n",
      " 'training_config': {'anneal_lr': True,\n",
      "                     'gamma': 0.99,\n",
      "                     'lr': 0.002,\n",
      "                     'num_envs': 100,\n",
      "                     'num_seeds': 2,\n",
      "                     'ppo_config': {'clip_eps': 0.2,\n",
      "                                    'entropy_coefficient': 0.01,\n",
      "                                    'gae_lambda': 0.95,\n",
      "                                    'is_clip_eps_per_env': False,\n",
      "                                    'max_grad_norm': 0.5,\n",
      "                                    'num_minibatches_actors': 4,\n",
      "                                    'num_steps_per_update': 256,\n",
      "                                    'update_epochs': 4,\n",
      "                                    'value_coefficient': 0.5},\n",
      "                     'seed': 1,\n",
      "                     'total_timesteps': 2000000.0},\n",
      " 'wandb_config': {'checkpoint_model_every_update_steps': 100.0,\n",
      "                  'entity': 'josssdan',\n",
      "                  'mode': 'online',\n",
      "                  'project': 'JaxInforMARL',\n",
      "                  'save_model': True}}\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:32.800775Z",
     "start_time": "2025-01-15T22:37:32.777954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_envs = config.training_config.num_envs\n",
    "num_agents = config.env_config.env_kwargs.num_agents\n",
    "num_steps = config.env_config.env_kwargs.max_steps"
   ],
   "id": "243953c079fafd50",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:33.520277Z",
     "start_time": "2025-01-15T22:37:32.813528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# reshaping so that the axis becomes num_env, num_steps, num_agents...\n",
    "\n",
    "traj_batch = jax.tree.map(lambda x: x.reshape(num_steps, num_agents, num_envs, *x.shape[2:]), traj_batch)\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 1, 2),\n",
    "    traj_batch,\n",
    ")\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 0, 1),\n",
    "    traj_batch,\n",
    ")\n"
   ],
   "id": "be320bcf7a38ca12",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:33.564911Z",
     "start_time": "2025-01-15T22:37:33.541986Z"
    }
   },
   "cell_type": "code",
   "source": "jax.tree.map(lambda x: x.shape, traj_batch)",
   "id": "c14560665810f9dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransitionWithEnvState(global_done=(100, 25, 2), done=(100, 25, 2), action=(100, 25, 2), value=(100, 25, 2), reward=(100, 25, 2), log_prob=(100, 25, 2), obs=(100, 25, 2, 6), graph=GraphsTupleWithAgentIndex(nodes=(100, 25, 2, 4, 7), edges=(100, 25, 2, 14, 1), receivers=(100, 25, 2, 14), senders=(100, 25, 2, 14), globals=None, n_node=(100, 25, 2), n_edge=(100, 25, 2), agent_indices=(100, 25, 2)), world_state=(100, 25, 2, 12), info={'returned_episode': (100, 25, 2), 'returned_episode_lengths': (100, 25, 2), 'returned_episode_returns': (100, 25, 2)}, env_state=LogEnvState(env_state=MPEState(dones=(100, 25, 2, 2), step=(100, 25, 2), entity_positions=(100, 25, 2, 4, 2), entity_velocities=(100, 25, 2, 4, 2), did_agent_die_this_time_step=(100, 25, 2, 2), agent_communication_message=(100, 25, 2, 0), agent_visibility_radius=(100, 25, 2, 2)), episode_returns=(100, 25, 2, 2), episode_lengths=(100, 25, 2, 2), returned_episode_returns=(100, 25, 2, 2), returned_episode_lengths=(100, 25, 2, 2)))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:33.643462Z",
     "start_time": "2025-01-15T22:37:33.585833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# summing across all steps in episode and across all agents\n",
    "total_reward = jnp.sum(traj_batch.reward, axis=(1, 2))\n",
    "avg_reward_per_episode = jnp.average(total_reward).item()"
   ],
   "id": "5825d20a7ead14fa",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:33.686642Z",
     "start_time": "2025-01-15T22:37:33.665580Z"
    }
   },
   "cell_type": "code",
   "source": "avg_reward_per_episode",
   "id": "e4dbf6617c2c421c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.56466674804688"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:33.986608Z",
     "start_time": "2025-01-15T22:37:33.707634Z"
    }
   },
   "cell_type": "code",
   "source": [
    "done = jnp.swapaxes(traj_batch.done, 1, 2)  # so that it becomes num_env, num_agents, num_steps\n",
    "avg_goal_reach_time_in_episode_fraction = (jnp.argmax(done, axis=-1) + 1) / num_steps\n",
    "agents_that_didnt_reach_goal = jnp.all(~done, axis=-1)\n",
    "avg_goal_reach_time_in_episode_fraction = avg_goal_reach_time_in_episode_fraction.at[agents_that_didnt_reach_goal].set(\n",
    "    1)\n",
    "avg_goal_reach_time_in_episode_fraction = jnp.average(avg_goal_reach_time_in_episode_fraction).item()"
   ],
   "id": "a86b2b58613252a6",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.113239Z",
     "start_time": "2025-01-15T22:37:34.089318Z"
    }
   },
   "cell_type": "code",
   "source": "avg_goal_reach_time_in_episode_fraction",
   "id": "59382adea20bab0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6273999810218811"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.222228Z",
     "start_time": "2025-01-15T22:37:34.134856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reached_goal = jnp.any(done, axis=-1)\n",
    "all_agents_reached_goal = jnp.all(reached_goal, axis=-1)\n",
    "\n",
    "episode_percent_all_agents_reached_goals = jnp.average(all_agents_reached_goal) * 100\n",
    "episode_percent_all_agents_reached_goals = episode_percent_all_agents_reached_goals.item()"
   ],
   "id": "ec21d308c41dda7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.264383Z",
     "start_time": "2025-01-15T22:37:34.244451Z"
    }
   },
   "cell_type": "code",
   "source": "episode_percent_all_agents_reached_goals",
   "id": "e5055b7e305080ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.306821Z",
     "start_time": "2025-01-15T22:37:34.286618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def compute_stats_for_all_episode(env, state):\n",
    "    compute_stats_for_every_step = jax.vmap(get_stats_for_state, in_axes=(None, 0))\n",
    "    compute_all_stats = jax.vmap(compute_stats_for_every_step, in_axes=(None, 0))\n",
    "    return compute_all_stats(env, state)"
   ],
   "id": "9ce79b5e0ff9a12",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.510708Z",
     "start_time": "2025-01-15T22:37:34.327677Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_state = traj_batch.env_state.env_state\n",
    "env_state = jax.tree.map(lambda x: x[:, :, 0],\n",
    "                         env_state)  # take state from one agent since it will be the same for all agents"
   ],
   "id": "d73db91942908241",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.617094Z",
     "start_time": "2025-01-15T22:37:34.535298Z"
    }
   },
   "cell_type": "code",
   "source": "num_collisions, num_agent_died = compute_stats_for_all_episode(env, env_state)",
   "id": "8463dc1c85054829",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.704156Z",
     "start_time": "2025-01-15T22:37:34.641265Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_num_collision_across_all_episodes = jnp.average(num_collisions).item()\n",
    "avg_num_deaths_across_all_episodes = jnp.average(num_agent_died).item()"
   ],
   "id": "57a3ae75722ef040",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.750278Z",
     "start_time": "2025-01-15T22:37:34.728531Z"
    }
   },
   "cell_type": "code",
   "source": "avg_reward_per_episode, avg_goal_reach_time_in_episode_fraction, episode_percent_all_agents_reached_goals, avg_num_collision_across_all_episodes",
   "id": "224b5df8a8442adc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180.56466674804688, 0.6273999810218811, 41.0, 0.025599999353289604)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-15T22:37:34.815730Z",
     "start_time": "2025-01-15T22:37:34.813850Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "aa9a8453a493855",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

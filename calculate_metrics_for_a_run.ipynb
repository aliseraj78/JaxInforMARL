{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:38.686003Z",
     "start_time": "2025-01-20T01:25:38.592210Z"
    }
   },
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "a03d32b1ca9a396f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:38.710353Z",
     "start_time": "2025-01-20T01:25:38.687395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "from calculate_metric import get_stats_for_state\n",
    "from visualize_actor import get_state_traj\n"
   ],
   "id": "8b024d1e9cfcad0",
   "outputs": [],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:42.349018Z",
     "start_time": "2025-01-20T01:25:38.711221Z"
    }
   },
   "source": [
    "artifact_version = \"455\"\n",
    "num_episodes = 100\n",
    "model_artifact_remote_name = (\n",
    "    f\"josssdan/JaxInforMARL/PPO_RNN_Runner_State:v{artifact_version}\"\n",
    ")\n",
    "\n",
    "traj_batch, config, env = get_state_traj(model_artifact_remote_name, artifact_version, num_episodes=num_episodes,\n",
    "                                         store_action_field=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'derived_values': {'minibatch_size': 19200,\n",
      "                    'num_actors': 300,\n",
      "                    'num_updates': 39,\n",
      "                    'scaled_clip_eps': 0.2},\n",
      " 'env_config': {'env_cls_name': 'TargetMPEEnvironment',\n",
      "                'env_kwargs': {'agent_communication_type': None,\n",
      "                               'agent_control_noise_std': 0.0,\n",
      "                               'agent_max_speed': -1,\n",
      "                               'agent_visibility_radius': [0.25],\n",
      "                               'collision_reward_coefficient': -1,\n",
      "                               'distance_to_goal_reward_coefficient': 10,\n",
      "                               'entities_initial_coord_radius': [1],\n",
      "                               'entity_acceleration': 5,\n",
      "                               'max_steps': 100,\n",
      "                               'num_agents': 3,\n",
      "                               'one_time_death_reward': 5}},\n",
      " 'network_config': {'actor_num_hidden_linear_layer': 2,\n",
      "                    'critic_num_hidden_linear_layer': 2,\n",
      "                    'entity_type_embedding_dim': 4,\n",
      "                    'fc_dim_size': 64,\n",
      "                    'graph_attention_key_dim': 16,\n",
      "                    'graph_hidden_feature_dim': 16,\n",
      "                    'graph_num_linear_layer': 3,\n",
      "                    'gru_hidden_dim': 64,\n",
      "                    'num_graph_attn_layers': 2,\n",
      "                    'num_heads_per_attn_layer': 3},\n",
      " 'training_config': {'anneal_lr': True,\n",
      "                     'gamma': 0.99,\n",
      "                     'lr': 0.0005,\n",
      "                     'num_envs': 100,\n",
      "                     'num_seeds': 2,\n",
      "                     'ppo_config': {'clip_eps': 0.2,\n",
      "                                    'entropy_coefficient': 0.01,\n",
      "                                    'gae_lambda': 0.95,\n",
      "                                    'is_clip_eps_per_env': False,\n",
      "                                    'max_grad_norm': 10,\n",
      "                                    'num_minibatches_actors': 4,\n",
      "                                    'num_steps_per_update': 256,\n",
      "                                    'update_epochs': 4,\n",
      "                                    'value_coefficient': 0.5},\n",
      "                     'seed': 65,\n",
      "                     'total_timesteps': 1000000.0},\n",
      " 'wandb_config': {'checkpoint_model_every_update_steps': 100.0,\n",
      "                  'entity': 'josssdan',\n",
      "                  'mode': 'online',\n",
      "                  'project': 'JaxInforMARL',\n",
      "                  'save_model': True}}\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:42.371673Z",
     "start_time": "2025-01-20T01:25:42.350072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_envs = config.training_config.num_envs\n",
    "num_agents = config.env_config.env_kwargs.num_agents\n",
    "num_steps = config.env_config.env_kwargs.max_steps"
   ],
   "id": "243953c079fafd50",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.168436Z",
     "start_time": "2025-01-20T01:25:42.372524Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# reshaping so that the axis becomes num_env, num_steps, num_agents...\n",
    "\n",
    "traj_batch = jax.tree.map(lambda x: x.reshape(num_steps, num_agents, num_envs, *x.shape[2:]), traj_batch)\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 1, 2),\n",
    "    traj_batch,\n",
    ")\n",
    "traj_batch = jax.tree.map(\n",
    "    lambda x: jnp.swapaxes(x, 0, 1),\n",
    "    traj_batch,\n",
    ")\n"
   ],
   "id": "be320bcf7a38ca12",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.190469Z",
     "start_time": "2025-01-20T01:25:43.169602Z"
    }
   },
   "cell_type": "code",
   "source": "jax.tree.map(lambda x: x.shape, traj_batch)",
   "id": "c14560665810f9dc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransitionForVisualization(global_done=(100, 100, 3), done=(100, 100, 3), action=(100, 100, 3), value=(100, 100, 3), reward=(100, 100, 3), log_prob=(100, 100, 3), obs=(100, 100, 3, 6), graph=GraphsTupleWithAgentIndex(nodes=(100, 100, 3, 6, 7), edges=(100, 100, 3, 21, 1), receivers=(100, 100, 3, 21), senders=(100, 100, 3, 21), globals=None, n_node=(100, 100, 3), n_edge=(100, 100, 3), agent_indices=(100, 100, 3)), world_state=(100, 100, 3, 18), info={'returned_episode': (100, 100, 3), 'returned_episode_lengths': (100, 100, 3), 'returned_episode_returns': (100, 100, 3)}, env_state=LogEnvState(env_state=MPEState(dones=(100, 100, 3, 3), step=(100, 100, 3), entity_positions=(100, 100, 3, 6, 2), entity_velocities=(100, 100, 3, 6, 2), did_agent_die_this_time_step=(100, 100, 3, 3), agent_communication_message=(100, 100, 3, 0), agent_visibility_radius=(100, 100, 3, 3)), episode_returns=(100, 100, 3, 3), episode_lengths=(100, 100, 3, 3), returned_episode_returns=(100, 100, 3, 3), returned_episode_lengths=(100, 100, 3, 3)))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.211368Z",
     "start_time": "2025-01-20T01:25:43.191391Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# summing across all steps in episode and across all agents\n",
    "total_reward = jnp.sum(traj_batch.reward, axis=(1, 2))\n",
    "avg_reward_per_episode = jnp.average(total_reward).item()"
   ],
   "id": "5825d20a7ead14fa",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.230545Z",
     "start_time": "2025-01-20T01:25:43.212088Z"
    }
   },
   "cell_type": "code",
   "source": "avg_reward_per_episode",
   "id": "e4dbf6617c2c421c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4757.55029296875"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.332064Z",
     "start_time": "2025-01-20T01:25:43.231362Z"
    }
   },
   "cell_type": "code",
   "source": [
    "done = jnp.swapaxes(traj_batch.done, 1, 2)  # so that it becomes num_env, num_agents, num_steps\n",
    "avg_goal_reach_time_in_episode_fraction = (jnp.argmax(done, axis=-1) + 1) / num_steps\n",
    "agents_that_didnt_reach_goal = jnp.all(~done, axis=-1)\n",
    "avg_goal_reach_time_in_episode_fraction = avg_goal_reach_time_in_episode_fraction.at[agents_that_didnt_reach_goal].set(\n",
    "    1)\n",
    "avg_goal_reach_time_in_episode_fraction = jnp.average(avg_goal_reach_time_in_episode_fraction).item()"
   ],
   "id": "a86b2b58613252a6",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.354482Z",
     "start_time": "2025-01-20T01:25:43.332910Z"
    }
   },
   "cell_type": "code",
   "source": "avg_goal_reach_time_in_episode_fraction",
   "id": "59382adea20bab0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1143999993801117"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.375523Z",
     "start_time": "2025-01-20T01:25:43.355448Z"
    }
   },
   "cell_type": "code",
   "source": [
    "reached_goal = jnp.any(done, axis=-1)\n",
    "all_agents_reached_goal = jnp.all(reached_goal, axis=-1)\n",
    "\n",
    "episode_percent_all_agents_reached_goals = jnp.average(all_agents_reached_goal) * 100\n",
    "episode_percent_all_agents_reached_goals = episode_percent_all_agents_reached_goals.item()"
   ],
   "id": "ec21d308c41dda7",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.396654Z",
     "start_time": "2025-01-20T01:25:43.376382Z"
    }
   },
   "cell_type": "code",
   "source": "episode_percent_all_agents_reached_goals",
   "id": "e5055b7e305080ad",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.418833Z",
     "start_time": "2025-01-20T01:25:43.397395Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@partial(jax.jit, static_argnums=(0,))\n",
    "def compute_stats_for_all_episode(env, state):\n",
    "    compute_stats_for_every_step = jax.vmap(get_stats_for_state, in_axes=(None, 0))\n",
    "    compute_all_stats = jax.vmap(compute_stats_for_every_step, in_axes=(None, 0))\n",
    "    return compute_all_stats(env, state)"
   ],
   "id": "9ce79b5e0ff9a12",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.440305Z",
     "start_time": "2025-01-20T01:25:43.419673Z"
    }
   },
   "cell_type": "code",
   "source": [
    "env_state = traj_batch.env_state.env_state\n",
    "env_state = jax.tree.map(lambda x: x[:, :, 0],\n",
    "                         env_state)  # take state from one agent since it will be the same for all agents"
   ],
   "id": "d73db91942908241",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.524226Z",
     "start_time": "2025-01-20T01:25:43.441104Z"
    }
   },
   "cell_type": "code",
   "source": "num_collisions, num_agent_died = compute_stats_for_all_episode(env, env_state)",
   "id": "8463dc1c85054829",
   "outputs": [],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.546877Z",
     "start_time": "2025-01-20T01:25:43.525149Z"
    }
   },
   "cell_type": "code",
   "source": [
    "avg_num_collision_across_all_episodes = jnp.average(num_collisions).item()\n",
    "avg_num_deaths_across_all_episodes = jnp.average(num_agent_died).item()"
   ],
   "id": "57a3ae75722ef040",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-20T01:25:43.567517Z",
     "start_time": "2025-01-20T01:25:43.547930Z"
    }
   },
   "cell_type": "code",
   "source": "avg_reward_per_episode, avg_goal_reach_time_in_episode_fraction, f\"{episode_percent_all_agents_reached_goals} %\", avg_num_collision_across_all_episodes",
   "id": "224b5df8a8442adc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-4757.55029296875, 0.1143999993801117, '100.0 %', 0.10584999620914459)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 35
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
